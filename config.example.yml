sources:
  markdown:
    path: examples              # готовые тестовые документы; замените на свой путь

qdrant:
  host: localhost
  port: 6333
  collection_docs: docs
  collection_chunks: chunks

llm:
  base_url: http://localhost:11434/v1
  model: qwen2.5-coder:7b
  api_key: ollama

indexing:
  chunker: passthrough          # passthrough | llm
  context: noop                 # noop | llm
  block_limit: 32000            # в llm-режиме автоматически ограничивается: min(block_limit, (llm_context_window - 512) / 2)
  llm_context_window: 32768     # контекстное окно LLM в токенах (qwen2.5: 32768, llama3: 8192, ...)
  dense_model: ai-forever/FRIDA
  sparse_model: Alibaba-NLP/gte-multilingual-base
  # sparse_device: mps            # cpu | mps | cuda | (not set = auto-detect)
