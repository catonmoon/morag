# Claude: устройство, возможности и инструкция по работе

Claude — семейство больших языковых моделей компании Anthropic. В отличие от большинства LLM, Claude создавался с акцентом на безопасность и управляемость с самого начала — это отражается как в архитектуре обучения, так и в поведении модели.

---

## Семейство моделей

### История версий

| Версия | Год | Ключевые изменения |
|---|---|---|
| Claude 1 | 2023 | Первый публичный релиз. Конституциональный AI как основа |
| Claude 2 | 2023 | Контекст 100k токенов, улучшенный coding и reasoning |
| Claude 2.1 | 2023 | Снижение галлюцинаций, честность при незнании |
| Claude 3 Haiku | 2024 | Быстрая и дешёвая модель для production |
| Claude 3 Sonnet | 2024 | Баланс скорость/качество |
| Claude 3 Opus | 2024 | Лучшее рассуждение в семействе, 200k контекст |
| Claude 3.5 Sonnet | 2024 | Превзошёл Opus по большинству бенчмарков |
| Claude 3.5 Haiku | 2024 | Быстрая модель уровня Claude 3 Sonnet |
| Claude 3.7 Sonnet | 2025 | Extended thinking, гибридный reasoning |
| Claude 4.5 Haiku | 2025 | Актуальная быстрая модель |
| Claude 4.6 Sonnet | 2025 | Актуальная основная модель |
| Claude 4.6 Opus | 2025 | Актуальная топовая модель |

### Идентификаторы моделей (API)

```python
from anthropic import Anthropic

client = Anthropic()

# Актуальные модели (февраль 2026)
MODELS = {
    'fast':    'claude-haiku-4-5-20251001',   # быстрый и дешёвый
    'default': 'claude-sonnet-4-6',            # основной выбор
    'best':    'claude-opus-4-6',              # максимальное качество
}
```

---

## Как устроено обучение Claude

### Constitutional AI (CAI)

Главное отличие Claude от GPT-семейства — **Constitutional AI**, разработанный Anthropic в 2022 году. Вместо того чтобы полностью полагаться на аннотации людей, модель обучается следовать набору принципов («конституции»):

```
Этап 1: SL-CAI (Supervised Learning)
  Модель генерирует ответ → критикует его по принципам конституции
  → переписывает ответ → обучается на переписанных ответах

Этап 2: RL-CAI (Reinforcement Learning)
  Вместо людей-аннотаторов → модель-критик оценивает пары ответов
  по конституции → обучение reward model → PPO/RLHF
```

Принципы конституции охватывают: вредоносность, честность, уважение к автономии пользователя, избегание манипуляций, соответствие правам человека.

### Harmlessness, Helpfulness, Honesty (HHH)

Anthropic декларирует три приоритета в порядке убывания:

1. **Harmless** — не причинять вред
2. **Helpful** — быть полезным
3. **Honest** — быть честным

На практике это означает: Claude скорее откажет в выполнении задачи, чем сделает что-то потенциально вредное. При этом Anthropic подчёркивает, что чрезмерная осторожность тоже нежелательна — отказывать там, где не нужно, тоже является провалом.

### Interpretability Research

Anthropic активно публикует исследования по механистической интерпретируемости (mechanistic interpretability) — пониманию того, что происходит внутри нейросети. Ключевые открытия:

- Линейные представления признаков в activation space
- «Моральные» концепции кодируются в отдельных направлениях пространства активаций
- Circuits — подграфы модели, отвечающие за конкретные алгоритмы

---

## Возможности и ограничения

### Сильные стороны

| Область | Описание |
|---|---|
| Длинный контекст | 200k токенов (~150k слов, ~500 страниц) у Opus и Sonnet |
| Кодирование | Сильный во всех популярных языках; хорошо понимает архитектуры |
| Следование инструкциям | Точно выполняет сложные многошаговые инструкции |
| Анализ документов | Выделяет ключевое, сравнивает, делает выводы |
| Русский язык | Свободно пишет и понимает; хуже, чем английский, но значительно лучше GPT-3 |
| Отказ от галлюцинаций | Чаще говорит «не знаю», чем выдумывает |
| Безопасное использование | Устойчив к jailbreak-атакам |

### Слабые стороны

| Область | Описание |
|---|---|
| Точная математика | Может ошибаться в вычислениях; лучше использовать Code Interpreter |
| Актуальность данных | Knowledge cutoff август 2025; свежие события неизвестны |
| Длинные генерации | Может «забыть» требования в начале длинного ответа |
| Уверенность | Иногда сомневается там, где можно быть уверенным |
| Изображения | Понимает, но не генерирует |

### Контекстное окно на практике

```
200 000 токенов ≈
  ├─ ~500 страниц текста
  ├─ ~150 000 слов
  ├─ ~10 000 строк кода
  └─ полный исходник средней Python-библиотеки
```

При работе с очень длинным контекстом качество может снижаться для информации из середины («lost in the middle» эффект). Информация в начале и конце контекста воспринимается лучше.

---

## API: как работать с Claude

### Базовый запрос

```python
import anthropic

client = anthropic.Anthropic(api_key="your-key")

message = client.messages.create(
    model="claude-sonnet-4-6",
    max_tokens=1024,
    messages=[
        {"role": "user", "content": "Объясни, что такое attention механизм"}
    ]
)
print(message.content[0].text)
```

### System prompt

System prompt задаёт роль, стиль и ограничения. Claude хорошо следует детальным инструкциям:

```python
message = client.messages.create(
    model="claude-sonnet-4-6",
    max_tokens=2048,
    system="""Ты технический писатель. Пишешь документацию для разработчиков.
Требования:
- Конкретно и без воды
- Всегда приводи примеры кода
- Используй markdown-форматирование
- Предупреждай о типичных ошибках
- Отвечай только по теме задачи""",
    messages=[
        {"role": "user", "content": "Напиши документацию для функции parse_config()"}
    ]
)
```

### Streaming

```python
with client.messages.stream(
    model="claude-sonnet-4-6",
    max_tokens=4096,
    messages=[{"role": "user", "content": "Напиши большой анализ..."}],
) as stream:
    for text in stream.text_stream:
        print(text, end="", flush=True)
```

### Tool Use (Function Calling)

```python
tools = [
    {
        "name": "search_documents",
        "description": "Поиск по базе знаний",
        "input_schema": {
            "type": "object",
            "properties": {
                "query": {"type": "string", "description": "Поисковый запрос"},
                "limit": {"type": "integer", "description": "Максимум результатов"},
            },
            "required": ["query"],
        },
    }
]

response = client.messages.create(
    model="claude-sonnet-4-6",
    max_tokens=1024,
    tools=tools,
    messages=[{"role": "user", "content": "Найди информацию о RoPE positional encoding"}],
)

# Если Claude решил вызвать инструмент:
if response.stop_reason == "tool_use":
    tool_call = next(b for b in response.content if b.type == "tool_use")
    print(tool_call.name)    # "search_documents"
    print(tool_call.input)   # {"query": "RoPE positional encoding", "limit": 5}
```

### Extended Thinking (Claude 3.7+)

Режим расширенного рассуждения — модель «думает вслух» перед ответом:

```python
response = client.messages.create(
    model="claude-sonnet-4-6",
    max_tokens=16000,
    thinking={
        "type": "enabled",
        "budget_tokens": 10000,  # сколько токенов потратить на рассуждение
    },
    messages=[{"role": "user", "content": "Реши задачу оптимизации..."}]
)

for block in response.content:
    if block.type == "thinking":
        print("Рассуждение:", block.thinking)
    elif block.type == "text":
        print("Ответ:", block.text)
```

---

## Эффективные техники промптинга

### 1. Давай роль и контекст

Плохо:
```
Переведи текст на английский.
```

Хорошо:
```
Ты профессиональный технический переводчик с опытом в IT.
Переведи следующий текст документации на английский язык.
Сохрани техническую терминологию, markdown-форматирование и примеры кода без изменений.

Текст:
[текст]
```

### 2. Структурируй сложные задачи

Claude хорошо следует пошаговым инструкциям:

```
Проанализируй этот код и сделай следующее:
1. Найди потенциальные баги
2. Оцени производительность (укажи O-нотацию)
3. Предложи рефакторинг с объяснением
4. Напиши unit-тесты для критических частей

Код:
[код]
```

### 3. Формат вывода

Явно укажи желаемый формат:

```
Ответь в формате JSON:
{
  "summary": "краткое резюме в 1-2 предложения",
  "issues": ["список проблем"],
  "recommendation": "итоговая рекомендация"
}
```

### 4. Chain-of-Thought

Для сложных рассуждений попроси думать пошагово:

```
Прежде чем ответить, разберись в задаче шаг за шагом.
Покажи ход рассуждений, а затем дай итоговый ответ.
```

### 5. Few-Shot примеры

Примеры работают лучше долгих описаний:

```
Преобразуй названия функций из camelCase в snake_case.

Примеры:
getUserName → get_user_name
parseHTMLDocument → parse_html_document
fetchAPIResponse → fetch_api_response

Теперь обработай:
calculateTotalPrice
```

### 6. Управление длиной ответа

```
# Краткий ответ
Объясни в 2-3 предложениях, что такое attention.

# Развёрнутый ответ
Напиши детальное объяснение с примерами кода и таблицами сравнения.

# Структурированный ответ
Ответ должен быть в пределах 500 слов, с заголовками и bullet points.
```

---

## Характер и предпочтения

### Что Claude любит

- **Точность формулировок** — если задача сформулирована чётко, ответ будет лучше
- **Настоящие задачи** — Claude охотнее помогает с реальными проектами, чем с абстрактными упражнениями
- **Обратную связь** — «это не то, что нужно, потому что...» помогает скорректировать направление
- **Технические детали** — не нужно упрощать; можно говорить на языке домена
- **Прямые вопросы** — «почему X работает так» лучше, чем «расскажи про X»

### Как Claude работает в диалоге

Claude воспринимает весь контекст разговора. Это означает:

- Можно давать уточнения («сделай короче», «добавь обработку ошибок»)
- Можно ссылаться на предыдущие ответы («используй тот же стиль»)
- Длинные разговоры влияют на качество — иногда лучше начать новый диалог с чётким контекстом

### Честность и неопределённость

Claude старается сигнализировать о неуверенности явно:

```
Я не уверен в этом факте — лучше проверить в официальной документации.
Это моё мнение, а не факт.
Мои знания ограничены датой обучения (август 2025).
```

Если Claude говорит что-то уверенно — это значит, что у него есть основания. Если сомневается — лучше перепроверить.

### Отказы и ограничения

Claude откажет в запросах, которые:
- Могут причинить реальный вред (оружие, кибератаки на продакшн, CSAM)
- Направлены на манипуляцию или обман конкретных людей
- Нарушают законы большинства юрисдикций

Claude **не** откажет в:
- Объяснении принципов работы вредоносного ПО (в образовательных целях)
- Написании кода для security-инструментов (CTF, пентестинг)
- Обсуждении спорных тем с разных точек зрения
- Создании художественного контента с тёмными темами

---

## Claude Code: специализированный режим

Claude Code — версия Claude, оптимизированная для работы с кодовыми базами прямо из терминала. Умеет:

- Читать и редактировать файлы
- Выполнять команды в терминале
- Искать по коду (grep, glob)
- Просматривать git-историю
- Создавать коммиты и PR

```bash
# Установка
npm install -g @anthropic-ai/claude-code

# Запуск в директории проекта
claude

# Примеры запросов:
> найди все места где используется устаревший API
> добавь обработку ошибок в функцию parse_config
> объясни как работает этот модуль
> прогони тесты и исправь упавшие
```

### Режимы работы Claude Code

| Режим | Описание |
|---|---|
| Default | Спрашивает подтверждение перед изменением файлов |
| Auto-approve | `--dangerously-skip-permissions` — без подтверждений |
| Plan mode | Сначала составляет план, потом реализует |
| Background agent | Запускает задачи асинхронно |

---

## Стоимость и лимиты (актуальные тарифы)

| Модель | Input (за 1M токенов) | Output (за 1M токенов) | Контекст |
|---|---|---|---|
| Claude Haiku 4.5 | $0.80 | $4 | 200k |
| Claude Sonnet 4.6 | $3 | $15 | 200k |
| Claude Opus 4.6 | $15 | $75 | 200k |

**Практические ориентиры:**
- 1 страница текста ≈ 500 токенов
- 100 строк кода ≈ 300–800 токенов (зависит от языка)
- Типичный диалог за сессию ≈ 5–50k токенов

### Кэширование промптов (Prompt Caching)

При повторных запросах с одинаковым system prompt или контекстом можно использовать кэширование:

```python
response = client.messages.create(
    model="claude-sonnet-4-6",
    max_tokens=1024,
    system=[
        {
            "type": "text",
            "text": "Большой системный промпт или контекст...",
            "cache_control": {"type": "ephemeral"},  # кэшировать этот блок
        }
    ],
    messages=[{"role": "user", "content": "Вопрос по контексту"}],
)
# Повторные запросы с тем же кэшированным блоком стоят в 10× дешевле
```

---

## Сравнение с другими моделями

| Характеристика | Claude Sonnet 4.6 | GPT-4o | Gemini 1.5 Pro |
|---|---|---|---|
| Контекст | 200k | 128k | 1M |
| Русский язык | Хорошо | Хорошо | Хорошо |
| Следование инструкциям | Очень высокое | Высокое | Высокое |
| Coding | Очень высокое | Высокое | Высокое |
| Отказы (overrefusal) | Умеренные | Умеренные | Редкие |
| Честность о незнании | Высокая | Средняя | Средняя |
| Цена (output) | $15/1M | $15/1M | $10.50/1M |
| API доступность | anthropic.com | openai.com | google.com |